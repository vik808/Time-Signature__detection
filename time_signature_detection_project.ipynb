{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "import tarfile\n",
        "import zipfile\n",
        "import glob\n",
        "from tqdm import tqdm  \n",
        "import librosa\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaWJPEhnfoce",
        "outputId": "af8f9ed2-388b-41de-be29-906168595551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meter\n",
            "3    1200\n",
            "4    1200\n",
            "5     200\n",
            "7     200\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load all three CSVs\n",
        "csv1 = pd.read_csv('/content/data_test_4_classes(1).csv')  # adjust sep if not tab\n",
        "csv2 = pd.read_csv('/content/data_train_4_classes(1).csv')\n",
        "csv3 = pd.read_csv('/content/data_val_4_classes.csv')\n",
        "\n",
        "# Concatenate into one DataFrame\n",
        "df = pd.concat([csv1, csv2, csv3], ignore_index=True)\n",
        "\n",
        "# Convert 'meter' to integer if it's not already\n",
        "df['meter'] = df['meter'].astype(int)\n",
        "\n",
        "# Filter for meters of interest\n",
        "target_meters = [3, 4, 5, 7]\n",
        "filtered = df[df['meter'].isin(target_meters)]\n",
        "\n",
        "# Count occurrences of each meter\n",
        "count_by_meter = filtered['meter'].value_counts().sort_index()\n",
        "\n",
        "print(count_by_meter)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af9_Onm_28Ns",
        "outputId": "57d08a44-6c1c-4f4c-f359-521625961c58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract tar & zip files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXACgNAWf8Yi",
        "outputId": "d9fc669f-d523-4b88-ca4d-45ec3b8d7aa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted FMA.tar.gz\n",
            "Extracted MAG.tar.gz\n",
            "Extracted OWN.tar.gz\n",
            "Successfully extracted: dl_data.zip\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/dl_dataset\"\n",
        "\n",
        "extract_path = \"/content/meter_2800/\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "for file in [\"FMA.tar.gz\", \"MAG.tar.gz\", \"OWN.tar.gz\"]:\n",
        "    file_path = os.path.join(dataset_path, file)\n",
        "    if os.path.exists(file_path):\n",
        "        with tarfile.open(file_path, \"r:gz\") as tar:\n",
        "            tar.extractall(extract_path)\n",
        "            print(f\"Extracted {file}\")\n",
        "\n",
        "zip_file_path = os.path.join(dataset_path, \"dl_data.zip\")\n",
        "\n",
        "if os.path.exists(zip_file_path):\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "            print(\"Successfully extracted: dl_data.zip\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(\" Error: dl_data.zip is not a valid zip file!\")\n",
        "else:\n",
        "    print(\" File not found: dl_data.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JF60TTJ3w1X",
        "outputId": "81f6cf86-d263-42e4-c60c-a2b666e32fbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "pip install pydub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Converting MP3 files to WAV files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAWLnAWGkHoa",
        "outputId": "852d8524-b7bd-4e8f-b329-952929f0f063"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Converting MP3 to WAV: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1882/1882 [09:27<00:00,  3.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " All MP3 files converted to WAV!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Paths\n",
        "input_dir = \"/content/meter_2800/\"  # Root folder containing FMA, MAG, OWN\n",
        "output_dir = \"/content/meter_2800_wav/\"  # Converted WAV files\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def convert_mp3_to_wav(mp3_path, output_dir):\n",
        "    \"\"\"Convert MP3 to WAV and save in output_dir\"\"\"\n",
        "    filename = os.path.basename(mp3_path).replace(\".mp3\", \".wav\")  # Change extension\n",
        "    wav_path = os.path.join(output_dir, filename)  # Save in output_dir\n",
        "    audio = AudioSegment.from_mp3(mp3_path)\n",
        "    audio.export(wav_path, format=\"wav\")\n",
        "    return wav_path\n",
        "\n",
        "# ğŸ” Find all MP3 files inside FMA, MAG, OWN (Recursive Search)\n",
        "mp3_files = glob.glob(os.path.join(input_dir, \"**\", \"*.mp3\"), recursive=True)\n",
        "\n",
        "# ğŸµ Convert all MP3 files to WAV\n",
        "wav_files = [convert_mp3_to_wav(mp3_file, output_dir) for mp3_file in tqdm(mp3_files, desc=\"Converting MP3 to WAV\")]\n",
        "\n",
        "print(\" All MP3 files converted to WAV!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSRKPCmvkSAb",
        "outputId": "61231e4f-0cf0-45b6-8838-920f32b1221a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting audiomentations\n",
            "  Downloading audiomentations-0.40.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting numpy<2,>=1.22.0 (from audiomentations)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n",
            "  Downloading numpy_minmax-0.4.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting numpy-rms<1,>=0.4.2 (from audiomentations)\n",
            "  Downloading numpy_rms-0.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting librosa!=0.10.0,<0.11.0,>=0.8.0 (from audiomentations)\n",
            "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting python-stretch<1,>=0.3.1 (from audiomentations)\n",
            "  Downloading python_stretch-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: scipy<2,>=1.4 in /usr/local/lib/python3.11/dist-packages (from audiomentations) (1.15.2)\n",
            "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from audiomentations) (0.5.0.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.13.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from numpy-minmax<1,>=0.3.0->audiomentations) (1.17.1)\n",
            "INFO: pip is looking at multiple versions of numpy-minmax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n",
            "  Downloading numpy_minmax-0.3.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "INFO: pip is looking at multiple versions of numpy-rms to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting numpy-rms<1,>=0.4.2 (from audiomentations)\n",
            "  Downloading numpy_rms-0.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy-loader>=0.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2025.1.31)\n",
            "Downloading audiomentations-0.40.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy_minmax-0.3.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading numpy_rms-0.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17 kB)\n",
            "Downloading python_stretch-0.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (113 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m113.4/113.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-stretch, numpy, numpy-rms, numpy-minmax, librosa, audiomentations\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.11.0\n",
            "    Uninstalling librosa-0.11.0:\n",
            "      Successfully uninstalled librosa-0.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed audiomentations-0.40.0 librosa-0.10.2.post1 numpy-1.26.4 numpy-minmax-0.3.1 numpy-rms-0.4.2 python-stretch-0.3.1\n"
          ]
        }
      ],
      "source": [
        "pip install audiomentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTBK4Xuy3OAa",
        "outputId": "15744124-8ca4-41df-acfa-a8e840ed938b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoliikOy3HhQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "FerZYzPSkYtn",
        "outputId": "13b57388-487e-4cf1-915d-412056517b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.1.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.3.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "70b32e9f19af4f4c8aa8aefc8b8b69a5",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install numpy==1.23.5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augmentation of Data for class 5 and 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FD9kDI0BaQv",
        "outputId": "77c5d017-2313-4f3d-82ad-8b63e6f6b35b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Original file counts per meter: {5: 193, 7: 198}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2873/2873 [24:15<00:00,  1.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ‰ Augmentation completed!\n",
            "âœ… Final augmented counts: {5: 1200, 7: 1200}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import soundfile as sf\n",
        "from scipy.signal import butter, lfilter\n",
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Gain, PolarityInversion\n",
        "\n",
        "# === Load Multiple Meter CSVs ===\n",
        "csv_files = [\n",
        "    '/content/data_train_4_classes(1).csv',\n",
        "    '/content/data_val_4_classes.csv',\n",
        "    '/content/data_test_4_classes(1).csv'\n",
        "]\n",
        "meter_df_list = [pd.read_csv(csv) for csv in csv_files]\n",
        "meter_df = pd.concat(meter_df_list, ignore_index=True)\n",
        "\n",
        "# Ensure the meter column is numeric\n",
        "meter_df['meter_num'] = meter_df['meter']\n",
        "\n",
        "# Create mapping from filename (basename) to meter\n",
        "filename_to_meter = dict(zip(meter_df['filename'].apply(os.path.basename), meter_df['meter_num']))\n",
        "\n",
        "# Target augment counts\n",
        "target_total = 1200\n",
        "target_meters = [5, 7]\n",
        "\n",
        "# Count current meter distribution\n",
        "meter_counts = meter_df['meter_num'].value_counts().to_dict()\n",
        "aug_counts = {5: meter_counts.get(5, 0), 7: meter_counts.get(7, 0)}\n",
        "\n",
        "# Input and output directories\n",
        "input_dirs = [\n",
        "    \"/content/meter_2800_wav/\",\n",
        "    \"/content/meter_2800/\"\n",
        "]\n",
        "output_dir = \"/content/drive/My Drive/Meter_2800_Augmented_1/\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Print original file counts per meter\n",
        "original_meter_counts = {5: 0, 7: 0}\n",
        "for input_dir in input_dirs:\n",
        "    for file in glob.glob(os.path.join(input_dir, \"**\", \"*.wav\"), recursive=True):\n",
        "        filename = os.path.basename(file)\n",
        "        meter = filename_to_meter.get(filename)\n",
        "        if meter in [5, 7]:\n",
        "            original_meter_counts[meter] += 1\n",
        "\n",
        "print(\"ğŸ“Š Original file counts per meter:\", original_meter_counts)\n",
        "\n",
        "# === Augmentation pipeline ===\n",
        "augment = Compose([\n",
        "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "    TimeStretch(min_rate=0.8, max_rate=1.2, p=0.5),\n",
        "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "    Gain(min_gain_db=-6, max_gain_db=6, p=0.5),\n",
        "    PolarityInversion(p=0.3)\n",
        "])\n",
        "\n",
        "def low_pass_filter(y, sr, cutoff=3000):\n",
        "    nyquist = 0.5 * sr\n",
        "    normal_cutoff = cutoff / nyquist\n",
        "    b, a = butter(5, normal_cutoff, btype=\"low\", analog=False)\n",
        "    return lfilter(b, a, y)\n",
        "\n",
        "def apply_augmentation(y, sr):\n",
        "    y = augment(samples=y, sample_rate=sr)\n",
        "    if random.random() < 0.5:\n",
        "        y = low_pass_filter(y, sr)\n",
        "    return y\n",
        "\n",
        "# === Find all WAV files ===\n",
        "wav_files = []\n",
        "for input_dir in input_dirs:\n",
        "    wav_files.extend(glob.glob(os.path.join(input_dir, \"**\", \"*.wav\"), recursive=True))\n",
        "\n",
        "# === Augment files ===\n",
        "for file_path in tqdm(wav_files, desc=\"Processing Files\"):\n",
        "    filename = os.path.basename(file_path)\n",
        "    meter = filename_to_meter.get(filename)\n",
        "\n",
        "    if meter not in target_meters:\n",
        "        continue\n",
        "\n",
        "    needed = target_total - aug_counts[meter]\n",
        "    if needed <= 0:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=None)\n",
        "        num_to_generate = min(needed, 10)  # Max 10 per file\n",
        "\n",
        "        for _ in range(num_to_generate):\n",
        "            y_aug = apply_augmentation(y, sr)\n",
        "            new_filename = f\"aug_{meter}_{aug_counts[meter]}_{filename}\"\n",
        "            sf.write(os.path.join(output_dir, new_filename), y_aug, sr)\n",
        "            aug_counts[meter] += 1\n",
        "\n",
        "            if aug_counts[meter] >= target_total:\n",
        "                break\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error processing {filename}: {e}\")\n",
        "\n",
        "print(\"\\n Augmentation completed!\")\n",
        "print(\" Final augmented counts:\", aug_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYuZCNzXpdb8",
        "outputId": "3937fd2f-d1ff-4914-ed6b-3ef314855367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Total files to extract features from: 4397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Mel Spectrograms: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4397/4397 [15:18<00:00,  4.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Extracted mel features for 4397 files.\n",
            " Features saved to: /content/drive/My Drive/Meter_2800_Features/\n",
            " Metadata CSV saved to: /content/drive/My Drive/Meter_2800_Features/mel_metadata.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# === Paths ===\n",
        "augmented_dir = \"/content/drive/My Drive/Meter_2800_Augmented_1/\"\n",
        "original_dirs = [\n",
        "    \"/content/meter_2800_wav/\",\n",
        "    \"/content/meter_2800/\"\n",
        "]\n",
        "output_dir = \"/content/drive/My Drive/Meter_2800_Features/\"\n",
        "output_csv = os.path.join(output_dir, \"mel_metadata.csv\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# === Load Time Signature Labels ===\n",
        "csv_files = [\n",
        "    \"/content/data_test_4_classes(1).csv\",\n",
        "    \"/content/data_train_4_classes(1).csv\",\n",
        "    \"/content/data_val_4_classes.csv\",\n",
        "]\n",
        "\n",
        "time_signature_map = {}\n",
        "meter_3_and_4_files = set()\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    try:\n",
        "        df = pd.read_csv(csv_file)\n",
        "        for _, row in df.iterrows():\n",
        "            filename = os.path.basename(row[\"filename\"])\n",
        "            meter = int(row[\"meter\"])\n",
        "            time_signature_map[filename] = f\"{meter}/4\"\n",
        "\n",
        "            # Track files with meter 3 and 4\n",
        "            if meter in [3, 4]:\n",
        "                meter_3_and_4_files.add(filename)\n",
        "    except Exception as e:\n",
        "        print(f\" Error reading {csv_file}: {e}\")\n",
        "\n",
        "# === Gather All Files ===\n",
        "all_files = []\n",
        "\n",
        "# 1. Augmented files (all)\n",
        "augmented_files = glob.glob(os.path.join(augmented_dir, \"*.wav\"))\n",
        "all_files.extend(augmented_files)\n",
        "\n",
        "# 2. Original files with meter 3 or 4 only\n",
        "for input_dir in original_dirs:\n",
        "    for file_path in glob.glob(os.path.join(input_dir, \"**\", \"*.wav\"), recursive=True):\n",
        "        filename = os.path.basename(file_path)\n",
        "        if filename in meter_3_and_4_files:\n",
        "            all_files.append(file_path)\n",
        "\n",
        "print(f\" Total files to extract features from: {len(all_files)}\")\n",
        "\n",
        "# === Feature Extraction ===\n",
        "metadata = []\n",
        "\n",
        "for file_path in tqdm(all_files, desc=\"Extracting Mel Spectrograms\"):\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "        # === Mel Spectrogram ===\n",
        "        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "        log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "        log_mel = (log_mel - log_mel.min()) / (log_mel.max() - log_mel.min() + 1e-6)\n",
        "\n",
        "        # === Save Feature ===\n",
        "        base_filename = os.path.basename(file_path).replace(\".wav\", \"\")\n",
        "        np.save(os.path.join(output_dir, f\"{base_filename}_mel.npy\"), log_mel)\n",
        "\n",
        "        # === Meter Detection ===\n",
        "        filename = os.path.basename(file_path)\n",
        "\n",
        "        if filename.startswith(\"aug_\"):\n",
        "            # Extract original filename from augmented name\n",
        "            original_filename = filename.split(\"_\")[-1]  # e.g. '00076.wav'\n",
        "        else:\n",
        "            original_filename = filename\n",
        "\n",
        "        meter = time_signature_map.get(original_filename, \"unknown\")\n",
        "\n",
        "        # === Metadata Entry ===\n",
        "        metadata.append([\n",
        "            filename, meter,\n",
        "            log_mel.shape[0], log_mel.shape[1]\n",
        "        ])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error processing {file_path}: {e}\")\n",
        "\n",
        "# === Save Metadata CSV ===\n",
        "df = pd.DataFrame(metadata, columns=[\n",
        "    \"filename\", \"meter\", \"mel_n_mels\", \"mel_n_frames\"\n",
        "])\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"\\n Extracted mel features for {len(df)} files.\")\n",
        "print(f\" Features saved to: {output_dir}\")\n",
        "print(f\" Metadata CSV saved to: {output_csv}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ResNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-cwG5kPHLSJZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torchvision.models import resnet18\n",
        "# ===== Dataset Class with Caching =====\n",
        "class CachedMelSpectrogramDataset(Dataset):\n",
        "    def __init__(self, metadata_df, feature_dir):\n",
        "        self.metadata_df = metadata_df.reset_index(drop=True)\n",
        "        self.feature_dir = feature_dir\n",
        "        self.label_map = {\"3/4\": 0, \"4/4\": 1, \"5/4\": 2, \"7/4\": 3}\n",
        "        self.cache = self._load_all()\n",
        "\n",
        "    def _load_all(self):\n",
        "        cache = []\n",
        "        for i in range(len(self.metadata_df)):\n",
        "            row = self.metadata_df.iloc[i]\n",
        "            fname = row['filename'].replace(\".wav\", \"\")\n",
        "            mel_file = os.path.join(self.feature_dir, f\"{fname}_mel.npy\")\n",
        "\n",
        "            try:\n",
        "                mel = np.load(mel_file)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {mel_file}: {e}\")\n",
        "                continue\n",
        "\n",
        "            mel = torch.from_numpy(mel).float().unsqueeze(0)\n",
        "            T_max = 1024\n",
        "            if mel.shape[2] < T_max:\n",
        "                mel = F.pad(mel, (0, T_max - mel.shape[2]))\n",
        "            else:\n",
        "                mel = mel[:, :, :T_max]\n",
        "\n",
        "            label = self.label_map.get(row['meter'], -1)\n",
        "            if label == -1:\n",
        "                continue\n",
        "            cache.append((mel, torch.tensor(label)))\n",
        "        return cache\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cache)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.cache[idx]\n",
        "\n",
        "def mel_collate_fn(batch):\n",
        "    mel_list, label_list = zip(*batch)\n",
        "    return torch.stack(mel_list), torch.tensor(label_list, dtype=torch.long)\n",
        "\n",
        "# ===== ResNet Model =====\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out)) + self.shortcut(x)\n",
        "        return F.relu(out)\n",
        "\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.resnet = nn.Sequential(\n",
        "            BasicBlock(1, 32, stride=2),\n",
        "            BasicBlock(32, 64, stride=2),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x).view(x.size(0), -1)\n",
        "\n",
        "\n",
        "class ResNetClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.resnet = resnet18(pretrained=False)\n",
        "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "# ===== Training and Evaluation =====\n",
        "def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, test_loss, test_acc, val_conf_matrices, test_conf_matrix, output_dir):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Val Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Train Acc')\n",
        "    plt.plot(val_accuracies, label='Val Acc')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.close()\n",
        "\n",
        "    for i, cm in enumerate(val_conf_matrices):\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "        disp.plot()\n",
        "        plt.title(f\"Validation Confusion Matrix Epoch {i+1}\")\n",
        "        plt.savefig(os.path.join(output_dir, f\"val_conf_matrix_epoch_{i+1}.png\"))\n",
        "        plt.close()\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=test_conf_matrix)\n",
        "    disp.plot()\n",
        "    plt.title(\"Test Confusion Matrix\")\n",
        "    plt.savefig(os.path.join(output_dir, \"test_conf_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    running_loss = 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for mel, label in dataloader:\n",
        "            mel, label = mel.to(device), label.to(device)\n",
        "            output = model(mel)\n",
        "            loss = criterion(output, label)\n",
        "            running_loss += loss.item()\n",
        "            _, pred = torch.max(output, 1)\n",
        "            correct += (pred == label).sum().item()\n",
        "            total += label.size(0)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_labels.extend(label.cpu().numpy())\n",
        "    accuracy = correct / total\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    return running_loss / len(dataloader), accuracy, cm\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, scaler, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    for mel, label in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        mel, label = mel.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            output = model(mel)\n",
        "            loss = criterion(output, label)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item()\n",
        "        _, pred = torch.max(output, 1)\n",
        "        correct += (pred == label).sum().item()\n",
        "        total += label.size(0)\n",
        "    accuracy = correct / total\n",
        "    return running_loss / len(dataloader), accuracy\n",
        "\n",
        "# ===== Training Loop with Chunking =====\n",
        "def train_on_chunks_fixed_split(metadata_path, feature_dir, output_dir, num_chunks=5, epochs_per_chunk=5, batch_size=32):\n",
        "    df = pd.read_csv(metadata_path)\n",
        "    df = df[df['meter'].isin([\"3/4\", \"4/4\", \"5/4\", \"7/4\"])].reset_index(drop=True)\n",
        "    train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['meter'], random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['meter'], random_state=42)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    val_ds = CachedMelSpectrogramDataset(val_df, feature_dir)\n",
        "    test_ds = CachedMelSpectrogramDataset(test_df, feature_dir)\n",
        "    val_dl = DataLoader(val_ds, batch_size=batch_size, collate_fn=mel_collate_fn)\n",
        "    test_dl = DataLoader(test_ds, batch_size=batch_size, collate_fn=mel_collate_fn)\n",
        "\n",
        "    model = ResNetClassifier(num_classes=4).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "    val_conf_matrices = []\n",
        "\n",
        "    chunk_size = len(train_df) // num_chunks\n",
        "    for i in range(num_chunks):\n",
        "        print(f\"\\nTraining on chunk {i+1}/{num_chunks}\")\n",
        "        chunk_df = train_df.iloc[i*chunk_size:] if i == num_chunks - 1 else train_df.iloc[i*chunk_size: (i+1)*chunk_size]\n",
        "        train_ds = CachedMelSpectrogramDataset(chunk_df, feature_dir)\n",
        "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=mel_collate_fn)\n",
        "\n",
        "        for epoch in range(1, epochs_per_chunk + 1):\n",
        "            train_loss, train_acc = train_one_epoch(model, train_dl, optimizer, criterion, scaler, device)\n",
        "            val_loss, val_acc, val_cm = evaluate(model, val_dl, criterion, device)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "            train_accuracies.append(train_acc)\n",
        "            val_accuracies.append(val_acc)\n",
        "            val_conf_matrices.append(val_cm)\n",
        "\n",
        "            print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "            model_path = os.path.join(output_dir, f\"resnet_chunk_{i+1}_epoch_{epoch}.pt\")\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        del train_dl, train_ds\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    test_loss, test_acc, test_cm = evaluate(model, test_dl, criterion, device)\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "    plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, test_loss, test_acc, val_conf_matrices, test_cm, output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pstQJYE4Lc0p",
        "outputId": "1525dddf-40f4-4c86-e0da-57cb241c08e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-2-3e3296402a8e>:191: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training on chunk 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 1.1376 | Train Acc: 55.05% | Val Acc: 22.95%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.9054 | Train Acc: 61.59% | Val Acc: 27.73%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.7976 | Train Acc: 65.43% | Val Acc: 60.45%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.7072 | Train Acc: 71.69% | Val Acc: 61.82%\n",
            "\n",
            "Training on chunk 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.8164 | Train Acc: 65.86% | Val Acc: 67.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.6997 | Train Acc: 72.83% | Val Acc: 65.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.6456 | Train Acc: 73.40% | Val Acc: 54.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.6282 | Train Acc: 73.83% | Val Acc: 74.32%\n",
            "\n",
            "Training on chunk 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.6544 | Train Acc: 74.25% | Val Acc: 68.18%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.6059 | Train Acc: 74.40% | Val Acc: 37.95%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.5617 | Train Acc: 78.81% | Val Acc: 70.68%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.5028 | Train Acc: 78.38% | Val Acc: 47.50%\n",
            "\n",
            "Training on chunk 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.6343 | Train Acc: 75.39% | Val Acc: 82.05%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.5431 | Train Acc: 76.96% | Val Acc: 64.77%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.4588 | Train Acc: 81.51% | Val Acc: 76.82%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.3850 | Train Acc: 85.06% | Val Acc: 76.59%\n",
            "\n",
            "Training on chunk 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/23 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.7259 | Train Acc: 73.76% | Val Acc: 54.32%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/23 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.6973 | Train Acc: 74.33% | Val Acc: 51.36%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/23 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.5603 | Train Acc: 80.43% | Val Acc: 60.45%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/23 [00:00<?, ?it/s]<ipython-input-2-3e3296402a8e>:160: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.5346 | Train Acc: 83.12% | Val Acc: 58.86%\n",
            "\n",
            "Final Test Accuracy: 57.73%\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_on_chunks_fixed_split(\n",
        "        metadata_path='/content/mel_metadata.csv',\n",
        "        feature_dir='/content/drive/MyDrive/Meter_2800_Features',\n",
        "        output_dir='/content/drive/MyDrive/Meter_Models_new_1/',\n",
        "        num_chunks=5,\n",
        "        epochs_per_chunk=4\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5E8zDFsYdlJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ===== Dataset Class with Caching =====\n",
        "class CachedMelSpectrogramDataset(Dataset):\n",
        "    def __init__(self, metadata_df, feature_dir):\n",
        "        self.metadata_df = metadata_df.reset_index(drop=True)\n",
        "        self.feature_dir = feature_dir\n",
        "        self.label_map = {\"3/4\": 0, \"4/4\": 1, \"5/4\": 2, \"7/4\": 3}\n",
        "        self.cache = self._load_all()\n",
        "\n",
        "    def _load_all(self):\n",
        "        cache = []\n",
        "        for i in range(len(self.metadata_df)):\n",
        "            row = self.metadata_df.iloc[i]\n",
        "            fname = row['filename'].replace(\".wav\", \"\")\n",
        "            mel_file = os.path.join(self.feature_dir, f\"{fname}_mel.npy\")\n",
        "\n",
        "            try:\n",
        "                mel = np.load(mel_file)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {mel_file}: {e}\")\n",
        "                continue\n",
        "\n",
        "            mel = torch.from_numpy(mel).float().unsqueeze(0)\n",
        "            T_max = 1024\n",
        "            if mel.shape[2] < T_max:\n",
        "                mel = F.pad(mel, (0, T_max - mel.shape[2]))\n",
        "            else:\n",
        "                mel = mel[:, :, :T_max]\n",
        "\n",
        "            label = self.label_map.get(row['meter'], -1)\n",
        "            if label == -1:\n",
        "                continue\n",
        "            cache.append((mel, torch.tensor(label)))\n",
        "        return cache\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cache)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.cache[idx]\n",
        "\n",
        "def mel_collate_fn(batch):\n",
        "    mel_list, label_list = zip(*batch)\n",
        "    return torch.stack(mel_list), torch.tensor(label_list, dtype=torch.long)\n",
        "\n",
        "# ===== Custom CNN Classifier =====\n",
        "class CustomCNNClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# ===== Training and Evaluation =====\n",
        "def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, test_loss, test_acc, val_conf_matrices, test_conf_matrix, output_dir):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Val Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Train Acc')\n",
        "    plt.plot(val_accuracies, label='Val Acc')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.close()\n",
        "\n",
        "    for i, cm in enumerate(val_conf_matrices):\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "        disp.plot()\n",
        "        plt.title(f\"Validation Confusion Matrix Epoch {i+1}\")\n",
        "        plt.savefig(os.path.join(output_dir, f\"val_conf_matrix_epoch_{i+1}.png\"))\n",
        "        plt.close()\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=test_conf_matrix)\n",
        "    disp.plot()\n",
        "    plt.title(\"Test Confusion Matrix\")\n",
        "    plt.savefig(os.path.join(output_dir, \"test_conf_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    running_loss = 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for mel, label in dataloader:\n",
        "            mel, label = mel.to(device), label.to(device)\n",
        "            output = model(mel)\n",
        "            loss = criterion(output, label)\n",
        "            running_loss += loss.item()\n",
        "            _, pred = torch.max(output, 1)\n",
        "            correct += (pred == label).sum().item()\n",
        "            total += label.size(0)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_labels.extend(label.cpu().numpy())\n",
        "    accuracy = correct / total\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    return running_loss / len(dataloader), accuracy, cm\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, scaler, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    for mel, label in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        mel, label = mel.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            output = model(mel)\n",
        "            loss = criterion(output, label)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item()\n",
        "        _, pred = torch.max(output, 1)\n",
        "        correct += (pred == label).sum().item()\n",
        "        total += label.size(0)\n",
        "    accuracy = correct / total\n",
        "    return running_loss / len(dataloader), accuracy\n",
        "\n",
        "# ===== Training Loop with Chunking =====\n",
        "def train_on_chunks_fixed_split(metadata_path, feature_dir, output_dir, num_chunks=5, epochs_per_chunk=5, batch_size=32):\n",
        "    df = pd.read_csv(metadata_path)\n",
        "    df = df[df['meter'].isin([\"3/4\", \"4/4\", \"5/4\", \"7/4\"])].reset_index(drop=True)\n",
        "    train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['meter'], random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['meter'], random_state=42)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    val_ds = CachedMelSpectrogramDataset(val_df, feature_dir)\n",
        "    test_ds = CachedMelSpectrogramDataset(test_df, feature_dir)\n",
        "    val_dl = DataLoader(val_ds, batch_size=batch_size, collate_fn=mel_collate_fn)\n",
        "    test_dl = DataLoader(test_ds, batch_size=batch_size, collate_fn=mel_collate_fn)\n",
        "\n",
        "    model = CustomCNNClassifier(num_classes=4).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "    val_conf_matrices = []\n",
        "\n",
        "    chunk_size = len(train_df) // num_chunks\n",
        "    for i in range(num_chunks):\n",
        "        print(f\"\\nTraining on chunk {i+1}/{num_chunks}\")\n",
        "        chunk_df = train_df.iloc[i*chunk_size:] if i == num_chunks - 1 else train_df.iloc[i*chunk_size: (i+1)*chunk_size]\n",
        "        train_ds = CachedMelSpectrogramDataset(chunk_df, feature_dir)\n",
        "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=mel_collate_fn)\n",
        "\n",
        "        for epoch in range(1, epochs_per_chunk + 1):\n",
        "            train_loss, train_acc = train_one_epoch(model, train_dl, optimizer, criterion, scaler, device)\n",
        "            val_loss, val_acc, val_cm = evaluate(model, val_dl, criterion, device)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "            train_accuracies.append(train_acc)\n",
        "            val_accuracies.append(val_acc)\n",
        "            val_conf_matrices.append(val_cm)\n",
        "\n",
        "            print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "            model_path = os.path.join(output_dir, f\"customcnn_chunk_{i+1}_epoch_{epoch}.pt\")\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        del train_dl, train_ds\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    test_loss, test_acc, test_cm = evaluate(model, test_dl, criterion, device)\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "    plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, test_loss, test_acc, val_conf_matrices, test_cm, output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YWWh0XJZTX9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(\"/content/output_dir/metrics_plot.png\")  # Adjust path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLj8dWgNY8c7",
        "outputId": "16e9ddc9-d6ac-4cc1-8bee-3bcb4841f721"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-c678a5ed8260>:176: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training on chunk 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 1.3764 | Train Acc: 29.02% | Val Acc: 42.05%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 1.3349 | Train Acc: 40.54% | Val Acc: 44.55%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 1.2081 | Train Acc: 46.80% | Val Acc: 44.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 1.1849 | Train Acc: 44.95% | Val Acc: 43.86%\n",
            "\n",
            "Training on chunk 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 1.2219 | Train Acc: 43.39% | Val Acc: 47.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 1.2032 | Train Acc: 44.81% | Val Acc: 46.36%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 1.2145 | Train Acc: 43.10% | Val Acc: 48.64%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 1.1963 | Train Acc: 45.52% | Val Acc: 48.41%\n",
            "\n",
            "Training on chunk 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 1.1944 | Train Acc: 46.51% | Val Acc: 48.18%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 1.2042 | Train Acc: 45.95% | Val Acc: 48.64%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 1.1904 | Train Acc: 47.37% | Val Acc: 47.73%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 1.1822 | Train Acc: 46.66% | Val Acc: 46.82%\n",
            "\n",
            "Training on chunk 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 1.1609 | Train Acc: 44.38% | Val Acc: 46.82%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 1.1670 | Train Acc: 45.66% | Val Acc: 47.27%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 1.1562 | Train Acc: 42.25% | Val Acc: 49.32%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 1.1615 | Train Acc: 45.23% | Val Acc: 48.64%\n",
            "\n",
            "Training on chunk 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/23 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 1.2091 | Train Acc: 44.68% | Val Acc: 49.55%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/23 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 1.1802 | Train Acc: 45.39% | Val Acc: 46.14%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/23 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 1.1607 | Train Acc: 45.53% | Val Acc: 48.86%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/23 [00:00<?, ?it/s]<ipython-input-7-c678a5ed8260>:145: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 1.1587 | Train Acc: 44.68% | Val Acc: 48.18%\n",
            "\n",
            "Final Test Accuracy: 48.64%\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_on_chunks_fixed_split(\n",
        "        metadata_path='/content/mel_metadata.csv',\n",
        "        feature_dir='/content/drive/MyDrive/Meter_2800_Features',\n",
        "        output_dir='/content/drive/MyDrive/Meter_Models_new_1/',\n",
        "        num_chunks=5,\n",
        "        epochs_per_chunk=4\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQhhOR6KarJQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ===== Dataset Class with Caching =====\n",
        "class CachedMelSpectrogramDataset(Dataset):\n",
        "    def __init__(self, metadata_df, feature_dir):\n",
        "        self.metadata_df = metadata_df.reset_index(drop=True)\n",
        "        self.feature_dir = feature_dir\n",
        "        self.label_map = {\"3/4\": 0, \"4/4\": 1, \"5/4\": 2, \"7/4\": 3}\n",
        "        self.cache = self._load_all()\n",
        "\n",
        "    def _load_all(self):\n",
        "        cache = []\n",
        "        for i in range(len(self.metadata_df)):\n",
        "            row = self.metadata_df.iloc[i]\n",
        "            fname = row['filename'].replace(\".wav\", \"\")\n",
        "            mel_file = os.path.join(self.feature_dir, f\"{fname}_mel.npy\")\n",
        "\n",
        "            try:\n",
        "                mel = np.load(mel_file)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {mel_file}: {e}\")\n",
        "                continue\n",
        "\n",
        "            mel = torch.from_numpy(mel).float().unsqueeze(0)\n",
        "            T_max = 1024\n",
        "            if mel.shape[2] < T_max:\n",
        "                mel = F.pad(mel, (0, T_max - mel.shape[2]))\n",
        "            else:\n",
        "                mel = mel[:, :, :T_max]\n",
        "\n",
        "            label = self.label_map.get(row['meter'], -1)\n",
        "            if label == -1:\n",
        "                continue\n",
        "            cache.append((mel, torch.tensor(label)))\n",
        "        return cache\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cache)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.cache[idx]\n",
        "\n",
        "def mel_collate_fn(batch):\n",
        "    mel_list, label_list = zip(*batch)\n",
        "    return torch.stack(mel_list), torch.tensor(label_list, dtype=torch.long)\n",
        "\n",
        "# ===== I Custom CNN Classifier =====\n",
        "class CustomCNNClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.GELU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.GELU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.GELU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.GELU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# ===== Training and Evaluation =====\n",
        "def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, test_loss, test_acc, val_conf_matrices, test_conf_matrix, output_dir):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Val Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Train Acc')\n",
        "    plt.plot(val_accuracies, label='Val Acc')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.close()\n",
        "\n",
        "    for i, cm in enumerate(val_conf_matrices):\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "        disp.plot()\n",
        "        plt.title(f\"Validation Confusion Matrix Epoch {i+1}\")\n",
        "        plt.savefig(os.path.join(output_dir, f\"val_conf_matrix_epoch_{i+1}.png\"))\n",
        "        plt.close()\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=test_conf_matrix)\n",
        "    disp.plot()\n",
        "    plt.title(\"Test Confusion Matrix\")\n",
        "    plt.savefig(os.path.join(output_dir, \"test_conf_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    running_loss = 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for mel, label in dataloader:\n",
        "            mel, label = mel.to(device), label.to(device)\n",
        "            output = model(mel)\n",
        "            loss = criterion(output, label)\n",
        "            running_loss += loss.item()\n",
        "            _, pred = torch.max(output, 1)\n",
        "            correct += (pred == label).sum().item()\n",
        "            total += label.size(0)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_labels.extend(label.cpu().numpy())\n",
        "    accuracy = correct / total\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    return running_loss / len(dataloader), accuracy, cm\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, scaler, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    for mel, label in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        mel, label = mel.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            output = model(mel)\n",
        "            loss = criterion(output, label)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item()\n",
        "        _, pred = torch.max(output, 1)\n",
        "        correct += (pred == label).sum().item()\n",
        "        total += label.size(0)\n",
        "    accuracy = correct / total\n",
        "    return running_loss / len(dataloader), accuracy\n",
        "\n",
        "# ===== Training Loop with Chunking =====\n",
        "def train_on_chunks_fixed_split(metadata_path, feature_dir, output_dir, num_chunks=5, epochs_per_chunk=5, batch_size=32):\n",
        "    df = pd.read_csv(metadata_path)\n",
        "    df = df[df['meter'].isin([\"3/4\", \"4/4\", \"5/4\", \"7/4\"])].reset_index(drop=True)\n",
        "    train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['meter'], random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['meter'], random_state=42)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    val_ds = CachedMelSpectrogramDataset(val_df, feature_dir)\n",
        "    test_ds = CachedMelSpectrogramDataset(test_df, feature_dir)\n",
        "    val_dl = DataLoader(val_ds, batch_size=batch_size, collate_fn=mel_collate_fn)\n",
        "    test_dl = DataLoader(test_ds, batch_size=batch_size, collate_fn=mel_collate_fn)\n",
        "\n",
        "    model = CustomCNNClassifier(num_classes=4).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "    val_conf_matrices = []\n",
        "\n",
        "    chunk_size = len(train_df) // num_chunks\n",
        "    for i in range(num_chunks):\n",
        "        print(f\"\\nTraining on chunk {i+1}/{num_chunks}\")\n",
        "        chunk_df = train_df.iloc[i*chunk_size:] if i == num_chunks - 1 else train_df.iloc[i*chunk_size: (i+1)*chunk_size]\n",
        "        train_ds = CachedMelSpectrogramDataset(chunk_df, feature_dir)\n",
        "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=mel_collate_fn)\n",
        "\n",
        "        for epoch in range(1, epochs_per_chunk + 1):\n",
        "            train_loss, train_acc = train_one_epoch(model, train_dl, optimizer, criterion, scaler, device)\n",
        "            val_loss, val_acc, val_cm = evaluate(model, val_dl, criterion, device)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "            train_accuracies.append(train_acc)\n",
        "            val_accuracies.append(val_acc)\n",
        "            val_conf_matrices.append(val_cm)\n",
        "\n",
        "            print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "            model_path = os.path.join(output_dir, f\"customcnn_chunk_{i+1}_epoch_{epoch}.pt\")\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        del train_dl, train_ds\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    test_loss, test_acc, test_cm = evaluate(model, test_dl, criterion, device)\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "    plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, test_loss, test_acc, val_conf_matrices, test_cm, output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98soBpmTav4i",
        "outputId": "c25fa629-c367-4923-94a3-42aa8571ed20"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-b1ca6d07ed46>:185: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training on chunk 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 1.0916 | Train Acc: 52.49% | Val Acc: 24.55%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.9245 | Train Acc: 61.88% | Val Acc: 32.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.8519 | Train Acc: 65.29% | Val Acc: 59.77%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.8279 | Train Acc: 65.86% | Val Acc: 63.41%\n",
            "\n",
            "Training on chunk 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.8571 | Train Acc: 63.58% | Val Acc: 48.41%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.8466 | Train Acc: 64.72% | Val Acc: 59.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.8077 | Train Acc: 66.00% | Val Acc: 65.68%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.7783 | Train Acc: 67.99% | Val Acc: 56.82%\n",
            "\n",
            "Training on chunk 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.8352 | Train Acc: 61.45% | Val Acc: 64.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.7724 | Train Acc: 66.15% | Val Acc: 67.73%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.7566 | Train Acc: 66.86% | Val Acc: 67.05%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.7369 | Train Acc: 66.00% | Val Acc: 62.05%\n",
            "\n",
            "Training on chunk 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.7338 | Train Acc: 65.29% | Val Acc: 62.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.7041 | Train Acc: 66.57% | Val Acc: 60.68%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.6608 | Train Acc: 69.27% | Val Acc: 61.36%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/22 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.6793 | Train Acc: 69.42% | Val Acc: 68.41%\n",
            "\n",
            "Training on chunk 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/23 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.7634 | Train Acc: 66.95% | Val Acc: 60.91%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/23 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.8252 | Train Acc: 67.80% | Val Acc: 57.05%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/23 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.7514 | Train Acc: 67.38% | Val Acc: 49.32%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/23 [00:00<?, ?it/s]<ipython-input-9-b1ca6d07ed46>:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.7917 | Train Acc: 66.52% | Val Acc: 69.55%\n",
            "\n",
            "Final Test Accuracy: 67.27%\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_on_chunks_fixed_split(\n",
        "        metadata_path='/content/mel_metadata.csv',\n",
        "        feature_dir='/content/drive/MyDrive/Meter_2800_Features',\n",
        "        output_dir='/content/drive/MyDrive/Meter_Models_new_2/',\n",
        "        num_chunks=5,\n",
        "        epochs_per_chunk=4\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzrIUHDRckkv",
        "outputId": "d348d227-e533-433a-80fe-1a862b53f605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting efficientnet-pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from efficientnet-pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->efficientnet-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->efficientnet-pytorch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=c205b0e0d49764d97fb07dc1312e01a8fe1bb0106d53bf1c104e71b1a407f075\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet-pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed efficientnet-pytorch-0.7.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install efficientnet-pytorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EfficientNet-B0 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UDYjmXgqloB",
        "outputId": "c81d9677-3b9f-43d5-8fbf-747b6745952b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n",
            "\n",
            "Training on chunk 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.9245 | Train Acc: 62.02% | Val Acc: 63.64%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.5681 | Train Acc: 77.95% | Val Acc: 60.68%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.3613 | Train Acc: 86.63% | Val Acc: 55.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.1926 | Train Acc: 93.60% | Val Acc: 60.91%\n",
            "\n",
            "Training on chunk 2/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.6548 | Train Acc: 76.96% | Val Acc: 33.18%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.3711 | Train Acc: 86.20% | Val Acc: 55.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.1803 | Train Acc: 94.17% | Val Acc: 57.05%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.1353 | Train Acc: 96.44% | Val Acc: 60.23%\n",
            "\n",
            "Training on chunk 3/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.4361 | Train Acc: 83.36% | Val Acc: 56.59%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.3162 | Train Acc: 87.48% | Val Acc: 64.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.1639 | Train Acc: 93.60% | Val Acc: 80.91%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.1219 | Train Acc: 95.31% | Val Acc: 76.14%\n",
            "\n",
            "Training on chunk 4/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.4138 | Train Acc: 85.35% | Val Acc: 74.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.2128 | Train Acc: 91.89% | Val Acc: 79.77%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.1201 | Train Acc: 95.73% | Val Acc: 83.18%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.0893 | Train Acc: 96.02% | Val Acc: 83.41%\n",
            "\n",
            "Training on chunk 5/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 0.4503 | Train Acc: 86.67% | Val Acc: 59.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Train Loss: 0.3301 | Train Acc: 91.49% | Val Acc: 76.36%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Train Loss: 0.2543 | Train Acc: 92.62% | Val Acc: 77.05%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Train Loss: 0.1400 | Train Acc: 97.02% | Val Acc: 79.32%\n",
            "\n",
            "Final Test Accuracy: 81.14%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import GradScaler, autocast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# ===== Dataset Class with Caching =====\n",
        "class CachedMelSpectrogramDataset(Dataset):\n",
        "    def __init__(self, metadata_df, feature_dir):\n",
        "        self.metadata_df = metadata_df.reset_index(drop=True)\n",
        "        self.feature_dir = feature_dir\n",
        "        self.label_map = {\"3/4\": 0, \"4/4\": 1, \"5/4\": 2, \"7/4\": 3}\n",
        "        self.cache = self._load_all()\n",
        "\n",
        "    def _load_all(self):\n",
        "        cache = []\n",
        "        for i in range(len(self.metadata_df)):\n",
        "            row = self.metadata_df.iloc[i]\n",
        "            fname = row['filename'].replace(\".wav\", \"\")\n",
        "            mel_file = os.path.join(self.feature_dir, f\"{fname}_mel.npy\")\n",
        "\n",
        "            try:\n",
        "                mel = np.load(mel_file)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {mel_file}: {e}\")\n",
        "                continue\n",
        "\n",
        "            mel = torch.from_numpy(mel).float().unsqueeze(0)  # [1, 128, T]\n",
        "            mel = mel.repeat(3, 1, 1)  # Convert to [3, 128, T] for EfficientNet\n",
        "            T_max = 1024\n",
        "            if mel.shape[2] < T_max:\n",
        "                mel = F.pad(mel, (0, T_max - mel.shape[2]))\n",
        "            else:\n",
        "                mel = mel[:, :, :T_max]\n",
        "\n",
        "            label = self.label_map.get(row['meter'], -1)\n",
        "            if label == -1:\n",
        "                continue\n",
        "            cache.append((mel, torch.tensor(label)))\n",
        "        return cache\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.cache)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.cache[idx]\n",
        "\n",
        "def mel_collate_fn(batch):\n",
        "    mel_list, label_list = zip(*batch)\n",
        "    return torch.stack(mel_list), torch.tensor(label_list, dtype=torch.long)\n",
        "\n",
        "# ===== EfficientNet-B0 Classifier =====\n",
        "class EfficientNetB0Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "        # Keep default conv stem (expects 3 channels)\n",
        "        in_features = self.model._fc.in_features\n",
        "        self.model._fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# ===== Training and Evaluation =====\n",
        "def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, test_loss, test_acc, val_conf_matrices, test_conf_matrix, output_dir):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_losses, label='Val Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Train Acc')\n",
        "    plt.plot(val_accuracies, label='Val Acc')\n",
        "    plt.title('Accuracy Over Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(os.path.join(output_dir, 'metrics_plot.png'))\n",
        "    plt.close()\n",
        "\n",
        "    for i, cm in enumerate(val_conf_matrices):\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "        disp.plot()\n",
        "        plt.title(f\"Validation Confusion Matrix Epoch {i+1}\")\n",
        "        plt.savefig(os.path.join(output_dir, f\"val_conf_matrix_epoch_{i+1}.png\"))\n",
        "        plt.close()\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=test_conf_matrix)\n",
        "    disp.plot()\n",
        "    plt.title(\"Test Confusion Matrix\")\n",
        "    plt.savefig(os.path.join(output_dir, \"test_conf_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    running_loss = 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for mel, label in dataloader:\n",
        "            mel, label = mel.to(device), label.to(device)\n",
        "            output = model(mel)\n",
        "            loss = criterion(output, label)\n",
        "            running_loss += loss.item()\n",
        "            _, pred = torch.max(output, 1)\n",
        "            correct += (pred == label).sum().item()\n",
        "            total += label.size(0)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_labels.extend(label.cpu().numpy())\n",
        "    accuracy = correct / total\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    return running_loss / len(dataloader), accuracy, cm\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, scaler, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    for mel, label in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        mel, label = mel.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(device_type='cuda'):\n",
        "            output = model(mel)\n",
        "            loss = criterion(output, label)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item()\n",
        "        _, pred = torch.max(output, 1)\n",
        "        correct += (pred == label).sum().item()\n",
        "        total += label.size(0)\n",
        "    accuracy = correct / total\n",
        "    return running_loss / len(dataloader), accuracy\n",
        "\n",
        "# ===== Training Loop with Chunking =====\n",
        "def train_on_chunks_fixed_split(metadata_path, feature_dir, output_dir, num_chunks=5, epochs_per_chunk=5, batch_size=32):\n",
        "    df = pd.read_csv(metadata_path)\n",
        "    df = df[df['meter'].isin([\"3/4\", \"4/4\", \"5/4\", \"7/4\"])].reset_index(drop=True)\n",
        "    train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['meter'], random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['meter'], random_state=42)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    val_ds = CachedMelSpectrogramDataset(val_df, feature_dir)\n",
        "    test_ds = CachedMelSpectrogramDataset(test_df, feature_dir)\n",
        "    val_dl = DataLoader(val_ds, batch_size=batch_size, collate_fn=mel_collate_fn)\n",
        "    test_dl = DataLoader(test_ds, batch_size=batch_size, collate_fn=mel_collate_fn)\n",
        "\n",
        "    model = EfficientNetB0Classifier(num_classes=4).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "    val_conf_matrices = []\n",
        "\n",
        "    chunk_size = len(train_df) // num_chunks\n",
        "    for i in range(num_chunks):\n",
        "        print(f\"\\nTraining on chunk {i+1}/{num_chunks}\")\n",
        "        chunk_df = train_df.iloc[i*chunk_size:] if i == num_chunks - 1 else train_df.iloc[i*chunk_size: (i+1)*chunk_size]\n",
        "        train_ds = CachedMelSpectrogramDataset(chunk_df, feature_dir)\n",
        "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=mel_collate_fn)\n",
        "\n",
        "        for epoch in range(1, epochs_per_chunk + 1):\n",
        "            train_loss, train_acc = train_one_epoch(model, train_dl, optimizer, criterion, scaler, device)\n",
        "            val_loss, val_acc, val_cm = evaluate(model, val_dl, criterion, device)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            val_losses.append(val_loss)\n",
        "            train_accuracies.append(train_acc)\n",
        "            val_accuracies.append(val_acc)\n",
        "            val_conf_matrices.append(val_cm)\n",
        "\n",
        "            print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}% | Val Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "            model_path = os.path.join(output_dir, f\"efficientnetb0_chunk_{i+1}_epoch_{epoch}.pt\")\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "\n",
        "        del train_dl, train_ds\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    test_loss, test_acc, test_cm = evaluate(model, test_dl, criterion, device)\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "    plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies, test_loss, test_acc, val_conf_matrices, test_cm, output_dir)\n",
        "\n",
        "# ===== Run Training =====\n",
        "if __name__ == \"__main__\":\n",
        "    train_on_chunks_fixed_split(\n",
        "        metadata_path=\"/content/mel_metadata.csv\",\n",
        "        feature_dir='/content/drive/MyDrive/Meter_2800_Features',\n",
        "        output_dir='/content/drive/MyDrive/Meter_Models_new_3/',\n",
        "        num_chunks=5,\n",
        "        epochs_per_chunk=4\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
